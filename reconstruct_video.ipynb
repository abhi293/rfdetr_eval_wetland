{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from rfdetr import RFDETRNano\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SOURCE_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\videos\"\n",
    "TARGET_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\annotated_videos\"\n",
    "ANNOTATIONS_PATH = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\_annotations.coco.json\"\n",
    "\n",
    "# Set your video range here (e.g., 40 to 70)\n",
    "# Note: Python indexing starts at 0. To get video \"040\", use index 39.\n",
    "START_INDEX = 39 \n",
    "END_INDEX = 70\n",
    "\n",
    "os.makedirs(TARGET_FOLDER, exist_ok=True)\n",
    "\n",
    "# 1. Initialize Model\n",
    "model = RFDETRNano(\n",
    "    patch_size=16,\n",
    "    positional_encoding_size=24,\n",
    "    resolution=384,\n",
    "    out_feature_indexes=[3, 6, 9, 12],\n",
    "    num_windows=2,\n",
    "    dec_layers=2,\n",
    "    pretrain_weights=\"rf-detr-nano.pth\"\n",
    ")\n",
    "# Optional: model.optimize_for_inference() \n",
    "\n",
    "# 2. Load and Index Ground Truth\n",
    "with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "filename_to_gt = {}\n",
    "for ann in coco_data['annotations']:\n",
    "    fname = image_id_to_filename[ann['image_id']]\n",
    "    if fname not in filename_to_gt:\n",
    "        filename_to_gt[fname] = []\n",
    "    # COCO [x,y,w,h] -> Supervision [x1,y1,x2,y2]\n",
    "    x, y, w, h = ann['bbox']\n",
    "    filename_to_gt[fname].append([x, y, x + w, y + h])\n",
    "\n",
    "# 3. Setup Video List with Limits\n",
    "all_video_files = sorted([f for f in os.listdir(SOURCE_FOLDER) if f.endswith('.mp4')])\n",
    "selected_videos = all_video_files[START_INDEX:END_INDEX]\n",
    "\n",
    "# 4. Storage for Evaluation\n",
    "all_predictions = []\n",
    "all_ground_truths = []\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "def process_frame(frame: np.ndarray, index: int, video_stem: str) -> np.ndarray:\n",
    "    # Construct filename to match COCO JSON (e.g., 001-white_wagtail_000000.jpg)\n",
    "    frame_filename = f\"{video_stem}_{index:06d}.jpg\"\n",
    "    \n",
    "    # Model Prediction\n",
    "    results = model.predict(frame, confidence=0.15)\n",
    "    bird_detections = results[results.class_id == 16] # Filter COCO 'Bird'\n",
    "    \n",
    "    # Map to Class 0 for Agnostic Evaluation\n",
    "    bird_detections.class_id = np.zeros_like(bird_detections.class_id)\n",
    "    \n",
    "    # Get Ground Truth\n",
    "    gt_boxes = filename_to_gt.get(frame_filename, [])\n",
    "    if gt_boxes:\n",
    "        gt_detections = sv.Detections(\n",
    "            xyxy=np.array(gt_boxes),\n",
    "            class_id=np.zeros(len(gt_boxes), dtype=int)\n",
    "        )\n",
    "    else:\n",
    "        gt_detections = sv.Detections.empty()\n",
    "\n",
    "    # Accumulate data\n",
    "    all_predictions.append(bird_detections)\n",
    "    all_ground_truths.append(gt_detections)\n",
    "    \n",
    "    # Annotation\n",
    "    labels = [f\"Bird {conf:.2f}\" for conf in bird_detections.confidence]\n",
    "    scene = box_annotator.annotate(scene=frame.copy(), detections=bird_detections)\n",
    "    return label_annotator.annotate(scene=scene, detections=bird_detections, labels=labels)\n",
    "\n",
    "# 5. Execution Loop\n",
    "print(f\"üöÄ Starting processing for videos {START_INDEX} through {END_INDEX}...\")\n",
    "\n",
    "for video_name in selected_videos:\n",
    "    stem = Path(video_name).stem\n",
    "    source_path = os.path.join(SOURCE_FOLDER, video_name)\n",
    "    target_path = os.path.join(TARGET_FOLDER, f\"{stem}_annotated.mp4\")\n",
    "    \n",
    "    print(f\"üé¨ Processing: {video_name}\")\n",
    "    sv.process_video(\n",
    "        source_path=source_path,\n",
    "        target_path=target_path,\n",
    "        callback=lambda f, i: process_frame(f, i, stem)\n",
    "    )\n",
    "\n",
    "# 6. Final Metrics Calculation\n",
    "print(\"\\nüìä Calculating Performance Metrics...\")\n",
    "\n",
    "# mAP\n",
    "map_metric = sv.MeanAveragePrecision.from_detections(\n",
    "    predictions=all_predictions,\n",
    "    ground_truth=all_ground_truths\n",
    ")\n",
    "\n",
    "# P, R, F1 via Confusion Matrix\n",
    "confusion_matrix = sv.ConfusionMatrix.from_detections(\n",
    "    predictions=all_predictions,\n",
    "    ground_truth=all_ground_truths,\n",
    "    classes=['Bird']\n",
    ")\n",
    "\n",
    "tp = confusion_matrix.matrix[0, 0]\n",
    "fp = confusion_matrix.matrix[0, 1]\n",
    "fn = confusion_matrix.matrix[1, 0]\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# 7. Save Reports\n",
    "metrics_report = {\n",
    "    \"Range_Processed\": f\"{START_INDEX} to {END_INDEX}\",\n",
    "    \"mAP_50\": round(float(map_metric.map50), 4),\n",
    "    \"mAP_50_95\": round(float(map_metric.map50_95), 4),\n",
    "    \"Precision\": round(float(precision), 4),\n",
    "    \"Recall\": round(float(recall), 4),\n",
    "    \"F1_Score\": round(float(f1), 4),\n",
    "    \"Total_Frames\": len(all_predictions)\n",
    "}\n",
    "\n",
    "# Export\n",
    "with open(os.path.join(TARGET_FOLDER, \"range_eval_results.json\"), \"w\") as f:\n",
    "    json.dump(metrics_report, f, indent=4)\n",
    "\n",
    "pd.DataFrame([metrics_report]).to_csv(os.path.join(TARGET_FOLDER, \"range_eval_summary.csv\"), index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Done! Performance for this range: F1={metrics_report['F1_Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import supervision as sv\n",
    "# from rfdetr import RFDETRNano\n",
    "\n",
    "# # 1. Initialize Model (Same settings as your inference script)\n",
    "# model = RFDETRNano(\n",
    "#     patch_size=16,\n",
    "#     positional_encoding_size=24,\n",
    "#     resolution=384,\n",
    "#     out_feature_indexes=[3, 6, 9, 12],\n",
    "#     num_windows=2,\n",
    "#     dec_layers=2,\n",
    "#     pretrain_weights=\"rf-detr-nano.pth\"\n",
    "# )\n",
    "\n",
    "# # 2. Paths\n",
    "# SOURCE_VIDEO = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\videos\\013-black_headed_gull.mp4\"\n",
    "# TARGET_VIDEO = r\"D:\\Projects\\RF_DETR_Wetland\\annotated_videos\\013-black_headed_gull_annotated.mp4\"\n",
    "\n",
    "# # 3. Setup Video Info and Tools\n",
    "# video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO)\n",
    "# box_annotator = sv.BoxAnnotator()\n",
    "# label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# # 4. Processing Function\n",
    "# def process_frame(frame: cv2.typing.MatLike, index: int) -> cv2.typing.MatLike:\n",
    "#     # Run AI prediction on the current frame\n",
    "#     results = model.predict(frame, confidence=0.15)\n",
    "    \n",
    "#     # Filter for ID 16 (Bird)\n",
    "#     bird_detections = results[results.class_id == 16]\n",
    "    \n",
    "#     # Annotate\n",
    "#     labels = [f\"Bird {conf:.2f}\" for conf in bird_detections.confidence]\n",
    "#     annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=bird_detections)\n",
    "#     annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=bird_detections, labels=labels)\n",
    "    \n",
    "#     return annotated_frame\n",
    "\n",
    "# # 5. Execute\n",
    "# print(f\"Processing {SOURCE_VIDEO}...\")\n",
    "# sv.process_video(\n",
    "#     source_path=SOURCE_VIDEO,\n",
    "#     target_path=TARGET_VIDEO,\n",
    "#     callback=process_frame\n",
    "# )\n",
    "# print(f\"Video saved at: {TARGET_VIDEO}\")\n",
    "\n",
    "import cv2\n",
    "import supervision as sv\n",
    "from rfdetr import RFDETRNano\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Initialize Model (Keeping your exact configurations)\n",
    "model = RFDETRNano(\n",
    "    patch_size=16,\n",
    "    positional_encoding_size=24,\n",
    "    resolution=384,\n",
    "    out_feature_indexes=[3, 6, 9, 12],\n",
    "    num_windows=2,\n",
    "    dec_layers=2,\n",
    "    pretrain_weights=\"rf-detr-nano.pth\"\n",
    ")\n",
    "\n",
    "# 2. Setup Directories\n",
    "SOURCE_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\videos\"\n",
    "TARGET_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\annotated_videos\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(TARGET_FOLDER, exist_ok=True)\n",
    "\n",
    "# 3. Setup Annotators\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# 4. Processing Function\n",
    "def process_frame(frame: cv2.typing.MatLike, index: int) -> cv2.typing.MatLike:\n",
    "    # Run AI prediction on the current frame\n",
    "    results = model.predict(frame, confidence=0.15)\n",
    "    \n",
    "    # Filter for ID 16 (Bird in COCO/General weights)\n",
    "    bird_detections = results[results.class_id == 16]\n",
    "    \n",
    "    # Annotate\n",
    "    labels = [f\"Bird {conf:.2f}\" for conf in bird_detections.confidence]\n",
    "    annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=bird_detections)\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=bird_detections, labels=labels)\n",
    "    \n",
    "    return annotated_frame\n",
    "\n",
    "# 5. Batch Execution Loop\n",
    "# Get all .mp4 files in the folder\n",
    "video_files = [f for f in os.listdir(SOURCE_FOLDER) if f.endswith('.mp4')]\n",
    "\n",
    "print(f\"Found {len(video_files)} videos. Starting batch processing...\")\n",
    "\n",
    "for video_filename in video_files:\n",
    "    source_path = os.path.join(SOURCE_FOLDER, video_filename)\n",
    "    \n",
    "    # Create target filename (e.g., bird_video.mp4 -> bird_video_annotated.mp4)\n",
    "    target_filename = f\"{Path(video_filename).stem}_annotated.mp4\"\n",
    "    target_path = os.path.join(TARGET_FOLDER, target_filename)\n",
    "    \n",
    "    print(f\"\\n--- Processing: {video_filename} ---\")\n",
    "    \n",
    "    try:\n",
    "        sv.process_video(\n",
    "            source_path=source_path,\n",
    "            target_path=target_path,\n",
    "            callback=process_frame\n",
    "        )\n",
    "        print(f\"Successfully saved to: {target_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_filename}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ All videos processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EVALUATION SCRIPT ---\n",
    "#this code evaluated the performance of re-detr-nano model on custom dataset visual wetland dataset using coco format annotations and supervision metrics for mAP, precision, recall, and F1 score. It processes a specified range of videos, extracts frames, runs predictions, and compares them to ground truth annotations to compute performance metrics which are then saved in JSON and CSV formats for analysis.\n",
    "#the model is initialized with specific configurations and pre-trained weights. The script loads COCO annotations, maps them to filenames, and processes videos in a defined range. For each frame, it predicts bird detections, compares them to ground truth, and accumulates results for final metric calculations. Finally, it computes mAP, precision, recall, and F1 score, saving the results in both JSON and CSV formats for further analysis.\n",
    "#the code uses supervision metrics for mAP, precision, recall, and F1 score, and can be easily modified to work with different datasets and models.\n",
    "#the ground truths for each frame have been extracyed from original visual wetland dataset and converted into _annotations.coco.json format for evaluation.\n",
    "\n",
    "\n",
    "import cv2\n",
    "import supervision as sv\n",
    "from rfdetr import RFDETRNano\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "SOURCE_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\videos\"\n",
    "ANNOTATIONS_PATH = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\_annotations.coco.json\"\n",
    "TARGET_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\evaluation_only\"\n",
    "os.makedirs(TARGET_FOLDER, exist_ok=True)\n",
    "\n",
    "START_IDX = 0\n",
    "STOP_IDX = 178\n",
    "\n",
    "# 1. Initialize Model\n",
    "model = RFDETRNano(\n",
    "    patch_size=16, positional_encoding_size=24, resolution=384,\n",
    "    out_feature_indexes=[3, 6, 9, 12], num_windows=2, dec_layers=2,\n",
    "    pretrain_weights=\"rf-detr-nano.pth\"\n",
    ")\n",
    "try:\n",
    "    model.optimize_for_inference()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 2. Initialize Evaluator (Updated for v0.27.0+)\n",
    "# We use the full path to the Metric class to avoid the DataClass conflict\n",
    "map_metric = sv.metrics.MeanAveragePrecision()\n",
    "\n",
    "# 3. Load Ground Truth Mapping\n",
    "with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "filename_to_gt = {}\n",
    "for ann in coco_data['annotations']:\n",
    "    fname = image_id_to_filename[ann['image_id']]\n",
    "    if fname not in filename_to_gt: filename_to_gt[fname] = []\n",
    "    x, y, w, h = ann['bbox']\n",
    "    filename_to_gt[fname].append([x, y, x + w, y + h])\n",
    "\n",
    "# 4. Prepare Videos\n",
    "all_video_files = sorted([f for f in os.listdir(SOURCE_FOLDER) if f.endswith('.mp4')])\n",
    "video_batch = all_video_files[START_IDX:STOP_IDX]\n",
    "\n",
    "print(f\"üöÄ Starting evaluation on {len(video_batch)} videos...\")\n",
    "\n",
    "# 5. Process Videos\n",
    "for video_name in video_batch:\n",
    "    stem = Path(video_name).stem\n",
    "    source_path = os.path.join(SOURCE_FOLDER, video_name)\n",
    "    cap = cv2.VideoCapture(source_path)\n",
    "    frame_idx = 0\n",
    "    \n",
    "    print(f\"üé¨ Processing: {video_name}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: break\n",
    "        \n",
    "        if frame_idx % 5 == 0:\n",
    "            frame_filename = f\"{stem}_{frame_idx:06d}.jpg\"\n",
    "            \n",
    "            # Predict\n",
    "            results = model.predict(frame, confidence=0.15)\n",
    "            bird_preds = results[results.class_id == 16]\n",
    "            # Force class 0 for agnostic evaluation\n",
    "            bird_preds.class_id = np.zeros_like(bird_preds.class_id)\n",
    "            \n",
    "            # Get GT\n",
    "            gt_boxes = filename_to_gt.get(frame_filename, [])\n",
    "            gt_detections = sv.Detections(\n",
    "                xyxy=np.array(gt_boxes),\n",
    "                class_id=np.zeros(len(gt_boxes), dtype=int)\n",
    "            ) if gt_boxes else sv.Detections.empty()\n",
    "\n",
    "            # Update evaluator incrementally\n",
    "            map_metric.update(bird_preds, gt_detections)\n",
    "            \n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "# 6. Compute & Save\n",
    "print(\"\\nüìä Generating Full Dataset Report...\")\n",
    "result = map_metric.compute()\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"mAP @ 50:95: {result.map50_95:.4f}\")\n",
    "print(f\"mAP @ 50:    {result.map50:.4f}\")\n",
    "print(f\"mAP @ 75:    {result.map75:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 7. Save to CSV\n",
    "# result.to_pandas() creates a detailed dataframe with all thresholds\n",
    "report_df = result.to_pandas()\n",
    "csv_path = os.path.join(TARGET_FOLDER, \"evaluation_report.csv\")\n",
    "report_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Results saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "from rfdetr import RFDETRMedium  # Changed from RFDETRNano\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# import time\n",
    "\n",
    "# --- CONFIG ---\n",
    "SOURCE_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\videos\"\n",
    "ANNOTATIONS_PATH = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\_annotations.coco.json\"\n",
    "TARGET_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\evaluation_only\"\n",
    "os.makedirs(TARGET_FOLDER, exist_ok=True)\n",
    "\n",
    "START_IDX = 0\n",
    "STOP_IDX = 178\n",
    "\n",
    "# 1. Initialize Model (Updated for Medium)\n",
    "model = RFDETRMedium(\n",
    "    patch_size=16, resolution=416,\n",
    "    pretrain_weights=\"rf-detr-medium.pth\"\n",
    ")\n",
    "\n",
    "# Optional: Optimize for inference (Recommended for Medium as it is heavier than Nano)\n",
    "try:\n",
    "    model.optimize_for_inference()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Optimization skipped: {e}\")\n",
    "\n",
    "# 2. Initialize Evaluator\n",
    "map_metric = sv.metrics.MeanAveragePrecision()\n",
    "\n",
    "# 3. Load Ground Truth Mapping\n",
    "with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "filename_to_gt = {}\n",
    "for ann in coco_data['annotations']:\n",
    "    fname = image_id_to_filename[ann['image_id']]\n",
    "    if fname not in filename_to_gt: filename_to_gt[fname] = []\n",
    "    x, y, w, h = ann['bbox']\n",
    "    filename_to_gt[fname].append([x, y, x + w, y + h])\n",
    "\n",
    "# 4. Prepare Videos\n",
    "all_video_files = sorted([f for f in os.listdir(SOURCE_FOLDER) if f.endswith('.mp4')])\n",
    "video_batch = all_video_files[START_IDX:STOP_IDX]\n",
    "\n",
    "print(f\"üöÄ Starting evaluation on {len(video_batch)} videos using RF-DETR-Medium...\")\n",
    "\n",
    "# 5. Process Videos\n",
    "for video_name in video_batch:\n",
    "    stem = Path(video_name).stem\n",
    "    source_path = os.path.join(SOURCE_FOLDER, video_name)\n",
    "    cap = cv2.VideoCapture(source_path)\n",
    "    frame_idx = 0\n",
    "    \n",
    "    print(f\"üé¨ Processing: {video_name}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: break\n",
    "        \n",
    "        if frame_idx % 5 == 0:\n",
    "            frame_filename = f\"{stem}_{frame_idx:06d}.jpg\"\n",
    "            \n",
    "            # Predict\n",
    "            # start_time = time.time()\n",
    "            results = model.predict(frame, confidence=0.15)\n",
    "            # inference_time = time.time() - start_time\n",
    "            # Filter for bird class (ID 16 in COCO)\n",
    "            bird_preds = results[results.class_id == 16]\n",
    "            # Force class 0 for agnostic evaluation\n",
    "            bird_preds.class_id = np.zeros_like(bird_preds.class_id)\n",
    "            \n",
    "            # print(f\"Frame: {frame_idx} | Time: {inference_time:.4f}s ({1/inference_time:.1f} FPS) | Birds: {len(bird_preds)}\")\n",
    "\n",
    "            # Get GT\n",
    "            gt_boxes = filename_to_gt.get(frame_filename, [])\n",
    "            gt_detections = sv.Detections(\n",
    "                xyxy=np.array(gt_boxes),\n",
    "                class_id=np.zeros(len(gt_boxes), dtype=int)\n",
    "            ) if gt_boxes else sv.Detections.empty()\n",
    "\n",
    "            # Update evaluator incrementally\n",
    "            map_metric.update(bird_preds, gt_detections)\n",
    "            \n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "# 6. Compute & Save\n",
    "print(\"\\nüìä Generating Full Dataset Report...\")\n",
    "result = map_metric.compute()\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"mAP @ 50:95: {result.map50_95:.4f}\")\n",
    "print(f\"mAP @ 50:    {result.map50:.4f}\")\n",
    "print(f\"mAP @ 75:    {result.map75:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 7. Save to CSV\n",
    "report_df = result.to_pandas()\n",
    "csv_path = os.path.join(TARGET_FOLDER, \"evaluation_report_medium_10.csv\")\n",
    "report_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Results saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebdecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rfdetr.main import download_pretrain_weights\n",
    "\n",
    "# try:\n",
    "#     print(\"Attempting to force-download Base weights...\")\n",
    "#     download_pretrain_weights(\"rf-detr-base.pth\", redownload=True)\n",
    "#     print(\"Download successful!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Download failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278760f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-17 19:01:04] [INFO] rf-detr - Loading pretrain weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting evaluation on 50 videos using RF-DETR-Base...\n",
      "üé¨ Processing: 001-white_wagtail.mp4\n",
      "üé¨ Processing: 002-squacco_heron.mp4\n",
      "üé¨ Processing: 003-squacco_heron.mp4\n",
      "üé¨ Processing: 004-squacco_heron.mp4\n",
      "üé¨ Processing: 005-squacco_heron.mp4\n",
      "üé¨ Processing: 006-yellow_legged_gull.mp4\n",
      "üé¨ Processing: 007-yellow_legged_gull.mp4\n",
      "üé¨ Processing: 008-yellow_legged_gull.mp4\n",
      "üé¨ Processing: 009-yellow_legged_gull.mp4\n",
      "üé¨ Processing: 010-yellow_legged_gull.mp4\n",
      "üé¨ Processing: 011-yellow_legged_gull.mp4\n"
     ]
    }
   ],
   "source": [
    "#test on base model \n",
    "\n",
    "import cv2\n",
    "import supervision as sv\n",
    "from rfdetr import RFDETRBase # Changed from RFDETRBase\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# import time\n",
    "\n",
    "# --- CONFIG ---\n",
    "SOURCE_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\videos\"\n",
    "ANNOTATIONS_PATH = r\"D:\\Projects\\RF_DETR_Wetland\\rf_detr\\_annotations.coco.json\"\n",
    "TARGET_FOLDER = r\"D:\\Projects\\RF_DETR_Wetland\\evaluation_only\"\n",
    "os.makedirs(TARGET_FOLDER, exist_ok=True)\n",
    "\n",
    "START_IDX = 0\n",
    "STOP_IDX = 50\n",
    "\n",
    "# 1. Initialize Model (Updated for Medium)\n",
    "model = RFDETRBase(\n",
    "    pretrain_weights=\"rf-detr-base.pth\"\n",
    ")\n",
    "\n",
    "# Optional: Optimize for inference (Recommended for Medium as it is heavier than Nano)\n",
    "try:\n",
    "    model.optimize_for_inference()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Optimization skipped: {e}\")\n",
    "\n",
    "# 2. Initialize Evaluator\n",
    "map_metric = sv.metrics.MeanAveragePrecision()\n",
    "\n",
    "# 3. Load Ground Truth Mapping\n",
    "with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "image_id_to_filename = {img['id']: img['file_name'] for img in coco_data['images']}\n",
    "filename_to_gt = {}\n",
    "for ann in coco_data['annotations']:\n",
    "    fname = image_id_to_filename[ann['image_id']]\n",
    "    if fname not in filename_to_gt: filename_to_gt[fname] = []\n",
    "    x, y, w, h = ann['bbox']\n",
    "    filename_to_gt[fname].append([x, y, x + w, y + h])\n",
    "\n",
    "# 4. Prepare Videos\n",
    "all_video_files = sorted([f for f in os.listdir(SOURCE_FOLDER) if f.endswith('.mp4')])\n",
    "video_batch = all_video_files[START_IDX:STOP_IDX]\n",
    "\n",
    "print(f\"üöÄ Starting evaluation on {len(video_batch)} videos using RF-DETR-Base...\")\n",
    "\n",
    "# 5. Process Videos\n",
    "for video_name in video_batch:\n",
    "    stem = Path(video_name).stem\n",
    "    source_path = os.path.join(SOURCE_FOLDER, video_name)\n",
    "    cap = cv2.VideoCapture(source_path)\n",
    "    frame_idx = 0\n",
    "    \n",
    "    print(f\"üé¨ Processing: {video_name}\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: break\n",
    "        \n",
    "        if frame_idx % 5 == 0:\n",
    "            frame_filename = f\"{stem}_{frame_idx:06d}.jpg\"\n",
    "            \n",
    "            # Predict\n",
    "            # start_time = time.time()\n",
    "            results = model.predict(frame, confidence=0.15)\n",
    "            # inference_time = time.time() - start_time\n",
    "            # Filter for bird class (ID 16 in COCO)\n",
    "            bird_preds = results[results.class_id == 16]\n",
    "            # Force class 0 for agnostic evaluation\n",
    "            bird_preds.class_id = np.zeros_like(bird_preds.class_id)\n",
    "            \n",
    "            # print(f\"Frame: {frame_idx} | Time: {inference_time:.4f}s ({1/inference_time:.1f} FPS) | Birds: {len(bird_preds)}\")\n",
    "\n",
    "            # Get GT\n",
    "            gt_boxes = filename_to_gt.get(frame_filename, [])\n",
    "            gt_detections = sv.Detections(\n",
    "                xyxy=np.array(gt_boxes),\n",
    "                class_id=np.zeros(len(gt_boxes), dtype=int)\n",
    "            ) if gt_boxes else sv.Detections.empty()\n",
    "\n",
    "            # Update evaluator incrementally\n",
    "            map_metric.update(bird_preds, gt_detections)\n",
    "            \n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "\n",
    "# 6. Compute & Save\n",
    "print(\"\\nüìä Generating Full Dataset Report...\")\n",
    "result = map_metric.compute()\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"mAP @ 50:95: {result.map50_95:.4f}\")\n",
    "print(f\"mAP @ 50:    {result.map50:.4f}\")\n",
    "print(f\"mAP @ 75:    {result.map75:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 7. Save to CSV\n",
    "report_df = result.to_pandas()\n",
    "csv_path = os.path.join(TARGET_FOLDER, \"evaluation_report_base_full.csv\")\n",
    "report_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Results saved to {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
